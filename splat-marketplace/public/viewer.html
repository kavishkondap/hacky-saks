<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>WebXR Splat Viewer + Capture</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Self-hosted scripts so COEP/COOP don't block them -->
    <script src="/vendor/aframe.min.js"></script>
    <script src="/vendor/aframe-gaussian-splatting.js"></script>

    <style>
      html, body { margin:0; height:100%; background:#000; }
      .hud {
        position: fixed; left: 8px; bottom: 8px; right: 8px; z-index: 20;
        background: rgba(0,0,0,.55); color: #fff; padding: 8px 10px; border-radius: 10px;
        font: 12px/1.45 ui-monospace, SFMono-Regular, Menlo, monospace;
      }
      .row { display:flex; gap:8px; flex-wrap: wrap; align-items: center; margin: 4px 0; }
      .mono { white-space: pre-wrap; }
      .ok { color:#9fe; } .warn { color:#ff9; } .err { color:#f99; }
      button { cursor:pointer; }
    </style>
  </head>
  <body>
    <div class="hud">
      <div class="row">Hold the <b>right trigger</b> to record. Release to stop.</div>
      <div id="status" class="row mono ok">idle</div>
      <div class="row"><button id="desktopTest">Desktop test (hold mouse)</button></div>
      <div id="result" class="row mono"></div>
    </div>

    <a-scene renderer="antialias: false" stats>
      <!-- Lights + sky so you always see something -->
      <a-entity light="type: ambient; color: #BBB; intensity: 0.8"></a-entity>
      <a-entity light="type: directional; color: #FFF; intensity: 0.9" position="1 3 -2"></a-entity>
      <a-sky color="#111"></a-sky>

      <!-- Camera rig -->
      <a-entity id="rig" position="0 1.6 0">
        <a-entity id="camera" camera look-controls wasd-controls></a-entity>
      </a-entity>

      <!-- Visual sanity check (unlit so it’s visible regardless of lights) -->
      <a-entity position="0 1.6 -2"
                animation="property: rotation; to: 0 360 0; dur: 10000; easing: linear; loop: true">
        <a-sphere position="0 0 0.5" radius="0.5" color="#FFFFFF" material="shader: flat"></a-sphere>
        <a-sphere position="0 0 -0.5" radius="0.5" color="#EF2D5E" material="shader: flat"></a-sphere>
      </a-entity>

      <!-- Controllers -->
      <a-entity id="left-controller"  oculus-touch-controls="hand: left"></a-entity>
      <a-entity id="right-controller" oculus-touch-controls="hand: right"
                capture-on-hold="button: a" trigger-capture></a-entity>

      <!-- Speaker to play synthesized reply -->
      <a-entity id="speaker" sound="positional: false; volume: 1.0"></a-entity>

      <!-- Gaussian splat -->
      <a-entity id="splat-viewer"
                position="0 1.5 -2" rotation="0 0 0" scale="1 1 1"
                gaussian_splatting="src: /public/train.splat;">
      </a-entity>
    </a-scene>

    <script>
      // --- URL param handling: src (splat), rot, pos ---
      (function () {
        const params = new URLSearchParams(window.location.search);
        const el = document.getElementById('splat-viewer');

        if (params.has('src')) {
          const raw = params.get('src'); // absolute or relative
          el.setAttribute('gaussian_splatting', `src: https://calhacks-hacky-saks.s3.us-east-2.amazonaws.com/${raw};`);
        }
        if (params.has('rot')) el.setAttribute('rotation', params.get('rot'));
        if (params.has('pos')) el.setAttribute('position', params.get('pos'));
      })();

      const statusEl = document.getElementById('status');
      const resultEl = document.getElementById('result');
      function status(msg, cls='ok'){ statusEl.className = 'row mono '+cls; statusEl.textContent = msg; }

      function blobToBase64(blob) {
        return new Promise((resolve, reject) => {
          const r = new FileReader();
          r.onloadend = () => resolve(String(r.result).split(',')[1]||'');
          r.onerror = reject;
          r.readAsDataURL(blob);
        });
      }

      // Better error surfaces
      async function readJsonOrText(res) {
        const txt = await res.text();
        try { return JSON.parse(txt); } catch { return { raw: txt }; }
      }
      function humanizeError(prefix, payload, status) {
        let msg = prefix;
        if (payload?.error) {
          if (typeof payload.error === 'string') msg += `: ${payload.error}`;
          else msg += `: ${JSON.stringify(payload.error)}`;
        } else if (payload?.message) {
          msg += `: ${payload.message}`;
        } else if (payload?.raw) {
          msg += `: ${payload.raw.slice(0, 300)}`;
        } else if (status) {
          msg += ` (status ${status})`;
        }
        return msg;
      }

      // --- A-button capture (kept) ---
      AFRAME.registerComponent('capture-on-hold', {
        schema: { button: { type:'string', default:'a' } },
        init() {
          this.mediaStream = null;
          this.mediaRecorder = null;
          this.chunks = [];
          this.recording = false;
          this._pendingScreenshot = null;

          const btn = this.data.button.toLowerCase();
          this.onDown = () => this.startCapture();
          this.onUp   = () => this.stopCapture();
          this.el.addEventListener(`${btn}buttondown`, this.onDown);
          this.el.addEventListener(`${btn}buttonup`,   this.onUp);
        },
        async startCapture() {
          if (this.recording) return;
          this.recording = true;

          const scene = this.el.sceneEl;
          const canvas = scene.canvas || scene.renderer?.domElement;
          const screenshotBlob = await new Promise(res => canvas.toBlob(res, 'image/png'));
          this._pendingScreenshot = screenshotBlob;

          try {
            this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          } catch (e) { status('mic permission denied', 'err'); this.recording = false; return; }
          this.chunks = [];
          this.mediaRecorder = new MediaRecorder(this.mediaStream, { mimeType: 'audio/webm' });
          this.mediaRecorder.ondataavailable = e => { if (e.data.size) this.chunks.push(e.data); };
          this.mediaRecorder.start();
          status('recording… (release A to stop)');
        },
        async stopCapture() {
          if (!this.recording) return;
          this.recording = false;

          await new Promise(resolve => { this.mediaRecorder.onstop = resolve; this.mediaRecorder.stop(); });
          this.mediaStream.getTracks().forEach(t => t.stop());
          const audioBlob = new Blob(this.chunks, { type: 'audio/webm' });

          // Fish ASR
          status('transcribing (Fish)…');
          let transcript = '';
          try {
            const form = new FormData();
            form.append('audio', audioBlob, 'clip.webm');
            const r = await fetch('/api/asr', { method: 'POST', body: form });
            const payload = await readJsonOrText(r);
            if (!r.ok) throw new Error(humanizeError('Fish STT failed', payload, r.status));
            transcript = payload.text || '';
          } catch (e) { console.error(e); status(String(e.message || e), 'err'); }

          // Claude
          status('asking Claude…');
          let output = '';
          try {
            const img = await blobToBase64(this._pendingScreenshot);
            const r = await fetch('/api/claude', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                transcript,
                image_base64: img,
                prompt: 'Analyze the VR scene image and the user transcript. Return a concise, helpful answer.'
              })
            });
            const payload = await readJsonOrText(r);
            if (!r.ok) throw new Error(humanizeError('Claude failed', payload, r.status));
            output = payload.output || '';
          } catch (e) { console.error(e); status(String(e.message || e), 'err'); }

          window.lastClaudeOutput = output;
          resultEl.textContent = output || '(no output)';
          status('done.');
          this._pendingScreenshot = null;
          this.mediaStream = null; this.mediaRecorder = null; this.chunks = [];
        }
      });

      // --- Right-trigger capture: screenshot + mic; then ASR -> Claude -> TTS ---
      AFRAME.registerComponent('trigger-capture', {
        init() {
          this.recording = false;
          this.mediaStream = null;
          this.mediaRecorder = null;
          this.chunks = [];
          this.screenshotBlob = null;

          this.onDown = () => this.startCapture();
          this.onUp   = () => this.stopAndProcess();

          this.el.addEventListener('triggerdown', this.onDown);
          this.el.addEventListener('triggerup',   this.onUp);
        },

        async startCapture() {
          if (this.recording) return;
          this.recording = true;

          // 1) Screenshot immediately
          const scene = this.el.sceneEl;
          const canvas = scene.canvas || scene.renderer?.domElement;
          this.screenshotBlob = await new Promise(res => canvas.toBlob(res, 'image/png'));

          // 2) Start mic
          try {
            this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          } catch (e) { status('mic permission denied', 'err'); this.recording = false; return; }

          this.chunks = [];
          this.mediaRecorder = new MediaRecorder(this.mediaStream, { mimeType: 'audio/webm' });
          this.mediaRecorder.ondataavailable = e => { if (e.data.size) this.chunks.push(e.data); };
          this.mediaRecorder.start();
          status('recording… (release trigger to stop)');
        },

        async stopAndProcess() {
          if (!this.recording) return;
          this.recording = false;

          // stop mic + collect audio
          await new Promise(r => { this.mediaRecorder.onstop = r; this.mediaRecorder.stop(); });
          this.mediaStream.getTracks().forEach(t => t.stop());
          const audioBlob = new Blob(this.chunks, { type: 'audio/webm' });

          // 3.1) Fish ASR
          status('transcribing (Fish)…');
          let transcript = '';
          try {
            const form = new FormData();
            form.append('audio', audioBlob, 'clip.webm');
            const r = await fetch('/api/asr', { method: 'POST', body: form });
            const payload = await readJsonOrText(r);
            if (!r.ok) throw new Error(humanizeError('Fish STT failed', payload, r.status));
            transcript = payload.text || '';
          } catch (e) { console.error(e); status(String(e.message || e), 'err'); }

          // 3.2) Claude
          status('asking Claude…');
          let answerText = '';
          try {
            const imgB64 = await blobToBase64(this.screenshotBlob);
            const r = await fetch('/api/claude', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                transcript,
                image_base64: imgB64,
                prompt: 'Analyze the VR scene image and the user transcript. Reply concisely and helpfully for audio playback.'
              })
            });
            const payload = await readJsonOrText(r);
            if (!r.ok) throw new Error(humanizeError('Claude failed', payload, r.status));
            answerText = (payload.output || '').trim();
          } catch (e) { console.error(e); status(String(e.message || e), 'err'); }

          // HUD
          window.lastClaudeOutput = answerText;
          resultEl.textContent = answerText || '(no output)';

          // 3.3) Fish TTS → play in-headset
          if (answerText) {
            status('synthesizing (Fish TTS)…');
            try {
              const r = await fetch('/api/tts', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ text: answerText, format: 'mp3' })
              });
              if (!r.ok) {
                const payload = await readJsonOrText(r);
                throw new Error(humanizeError('TTS failed', payload, r.status));
              }
              const buf = await r.arrayBuffer();
              const url = URL.createObjectURL(new Blob([buf], { type: 'audio/mpeg' }));

              // Play via A-Frame sound (works on Quest)
              const speaker = document.querySelector('#speaker');
              speaker.setAttribute('sound', 'src', url);
              if (speaker.components.sound) {
                try { speaker.components.sound.stop(); } catch {}
                speaker.components.sound.playSound();
              } else {
                new Audio(url).play().catch(()=>{});
              }

              // optional: reclaim URL after playback (best effort)
              const a = speaker.components.sound?.pool?.[0]?.audioEl;
              if (a) {
                const revoke = () => { URL.revokeObjectURL(url); a.removeEventListener('ended', revoke); };
                a.addEventListener('ended', revoke);
              }

              status('done.');
            } catch (e) { console.error(e); status(String(e.message || e), 'err'); }
          } else {
            status('done.');
          }

          // cleanup
          this.mediaStream = null;
          this.mediaRecorder = null;
          this.chunks = [];
          this.screenshotBlob = null;
        }
      });

      // --- Desktop test button (mouse hold) ---
      (function() {
        const btn = document.getElementById('desktopTest');
        let rec=null, stream=null, chunks=[], screenshotBlob=null;
        btn.onmousedown = async () => {
          const scene = document.querySelector('a-scene');
          const canvas = scene.canvas || scene.renderer?.domElement;
          screenshotBlob = await new Promise(res => canvas.toBlob(res, 'image/png'));
          try { stream = await navigator.mediaDevices.getUserMedia({ audio: true }); }
          catch (e) { status('mic denied (desktop test)', 'err'); return; }
          chunks=[]; rec = new MediaRecorder(stream, { mimeType: 'audio/webm' });
          rec.ondataavailable = e => { if (e.data.size) chunks.push(e.data); };
          rec.start(); status('recording… (release mouse to stop)');
        };
        btn.onmouseup = async () => {
          if (!rec) return;
          await new Promise(r => { rec.onstop = r; rec.stop(); });
          stream.getTracks().forEach(t => t.stop());
          const audioBlob = new Blob(chunks, { type:'audio/webm' });

          // ASR
          status('transcribing (Fish)…');
          let transcript=''; try{
            const f = new FormData(); f.append('audio', audioBlob, 'clip.webm');
            const r = await fetch('/api/asr', { method:'POST', body:f });
            const p = await readJsonOrText(r);
            if (!r.ok) throw new Error(humanizeError('Fish STT failed', p, r.status));
            transcript = p.text||'';
          }catch(e){ console.error(e); status(String(e.message||e),'err'); }

          // Claude
          let txt=''; try{
            const b64 = await blobToBase64(screenshotBlob);
            const r = await fetch('/api/claude', {
              method:'POST', headers:{'Content-Type':'application/json'},
              body: JSON.stringify({ transcript, image_base64: b64, prompt: 'Describe key details and insights.' })
            });
            const p = await readJsonOrText(r);
            if (!r.ok) throw new Error(humanizeError('Claude failed', p, r.status));
            txt = p.output||'';
          }catch(e){ console.error(e); status(String(e.message||e),'err'); }

          // TTS + play
          if (txt) {
            try{
              const r = await fetch('/api/tts', {
                method:'POST', headers:{'Content-Type':'application/json'},
                body: JSON.stringify({ text: txt, format:'mp3' })
              });
              if (!r.ok) {
                const p = await readJsonOrText(r);
                throw new Error(humanizeError('TTS failed', p, r.status));
              }
              const buf = await r.arrayBuffer();
              const url = URL.createObjectURL(new Blob([buf], { type: 'audio/mpeg' }));
              const speaker = document.querySelector('#speaker');
              speaker.setAttribute('sound', 'src', url);
              if (speaker.components.sound) {
                try { speaker.components.sound.stop(); } catch {}
                speaker.components.sound.playSound();
              } else {
                new Audio(url).play().catch(()=>{});
              }
              status('done.');
            }catch(e){ console.error(e); status(String(e.message||e),'err'); }
          } else {
            resultEl.textContent = '(no output)'; status('done.');
          }
        };
        btn.onmouseleave = btn.onmouseup;
      })();

      // Diagnostics
      window.addEventListener('error', (e) => console.error('Viewer error:', e.error || e.message));
      AFRAME.scenes && AFRAME.scenes[0]?.addEventListener('loaded', () => console.log('A-Frame scene loaded'));
    </script>
  </body>
</html>
